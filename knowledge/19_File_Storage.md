# Domain 19: File Storage & Upload

> **S·ªë practices:** 10 | üî¥ 3 | üü† 4 | üü° 3
> **Tr·ªçng s·ªë:** √ó1

---

## 19.01 - File type validation (MIME type + magic bytes, kh√¥ng ch·ªâ extension)

### Metadata
- **M·ª©c ƒë·ªô:** üî¥ B·∫ÆT BU·ªòC
- **L√Ω do:** Security - ngƒÉn ch·∫∑n upload file ƒë·ªôc h·∫°i, bypass extension
- **Impact:** HIGH - RCE, malware upload, XSS
- **Tags:** `security`, `validation`, `upload`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- Extension c√≥ th·ªÉ fake d·ªÖ d√†ng (`virus.exe` ‚Üí `virus.jpg`)
- MIME type t·ª´ client c√≥ th·ªÉ gi·∫£ m·∫°o
- Magic bytes (file signature) l√† c√°ch ƒë√°ng tin c·∫≠y nh·∫•t

**H·∫≠u qu·∫£ khi vi ph·∫°m:**
- Upload shell script gi·∫£ d·∫°ng image
- RCE n·∫øu file ƒë∆∞·ª£c execute
- XSS qua SVG ƒë·ªôc h·∫°i
- Malware distribution

### ‚úÖ C√°ch ƒë√∫ng

```java
// ‚úÖ GOOD: Validate c·∫£ MIME type + magic bytes
@Service
public class FileValidationService {

  private static final Map<String, byte[]> ALLOWED_SIGNATURES = Map.of(
    "image/jpeg", new byte[]{(byte) 0xFF, (byte) 0xD8, (byte) 0xFF},
    "image/png", new byte[]{(byte) 0x89, 0x50, 0x4E, 0x47},
    "application/pdf", new byte[]{0x25, 0x50, 0x44, 0x46}
  );

  private static final Set<String> ALLOWED_MIME_TYPES = Set.of(
    "image/jpeg", "image/png", "application/pdf"
  );

  public void validateFile(MultipartFile file) {
    // 1. Check extension
    String filename = file.getOriginalFilename();
    if (!hasAllowedExtension(filename)) {
      throw new InvalidFileException("Extension kh√¥ng ƒë∆∞·ª£c ph√©p");
    }

    // 2. Check MIME type
    String contentType = file.getContentType();
    if (!ALLOWED_MIME_TYPES.contains(contentType)) {
      throw new InvalidFileException("MIME type kh√¥ng ƒë∆∞·ª£c ph√©p: " + contentType);
    }

    // 3. Check magic bytes (file signature)
    try {
      byte[] fileBytes = file.getBytes();
      if (!hasValidMagicBytes(fileBytes, contentType)) {
        throw new InvalidFileException("File signature kh√¥ng kh·ªõp v·ªõi MIME type");
      }
    } catch (IOException e) {
      throw new InvalidFileException("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file content");
    }
  }

  private boolean hasValidMagicBytes(byte[] fileBytes, String mimeType) {
    byte[] expectedSignature = ALLOWED_SIGNATURES.get(mimeType);
    if (expectedSignature == null) return false;

    if (fileBytes.length < expectedSignature.length) return false;

    for (int i = 0; i < expectedSignature.length; i++) {
      if (fileBytes[i] != expectedSignature[i]) {
        return false;
      }
    }
    return true;
  }

  private boolean hasAllowedExtension(String filename) {
    if (filename == null) return false;
    String ext = filename.substring(filename.lastIndexOf('.') + 1).toLowerCase();
    return Set.of("jpg", "jpeg", "png", "pdf").contains(ext);
  }
}

// ‚úÖ GOOD: S·ª≠ d·ª•ng Apache Tika ƒë·ªÉ detect MIME type ch√≠nh x√°c
@Service
public class TikaFileValidator {

  private final Tika tika = new Tika();

  public void validateFile(MultipartFile file) throws IOException {
    // Detect MIME type t·ª´ file content
    String detectedMimeType = tika.detect(file.getBytes());

    // So s√°nh v·ªõi MIME type t·ª´ client
    String declaredMimeType = file.getContentType();

    if (!detectedMimeType.equals(declaredMimeType)) {
      throw new InvalidFileException(
        "MIME type kh√¥ng kh·ªõp. Declared: %s, Detected: %s"
          .formatted(declaredMimeType, detectedMimeType)
      );
    }

    // Ki·ªÉm tra whitelist
    if (!Set.of("image/jpeg", "image/png", "application/pdf").contains(detectedMimeType)) {
      throw new InvalidFileException("File type kh√¥ng ƒë∆∞·ª£c ph√©p: " + detectedMimeType);
    }
  }
}

// ‚úÖ GOOD: Custom validator annotation
@Target(ElementType.PARAMETER)
@Retention(RetentionPolicy.RUNTIME)
@Constraint(validatedBy = FileTypeValidator.class)
public @interface ValidFileType {
  String message() default "File type kh√¥ng h·ª£p l·ªá";
  Class<?>[] groups() default {};
  Class<? extends Payload>[] payload() default {};
  String[] allowed() default {"image/jpeg", "image/png"};
}

public class FileTypeValidator implements ConstraintValidator<ValidFileType, MultipartFile> {

  private Set<String> allowedTypes;
  private final Tika tika = new Tika();

  @Override
  public void initialize(ValidFileType annotation) {
    this.allowedTypes = Set.of(annotation.allowed());
  }

  @Override
  public boolean isValid(MultipartFile file, ConstraintValidatorContext context) {
    if (file == null || file.isEmpty()) return true;

    try {
      String detectedType = tika.detect(file.getBytes());
      return allowedTypes.contains(detectedType);
    } catch (IOException e) {
      return false;
    }
  }
}

// Controller usage
@PostMapping("/upload")
public ResponseEntity<?> upload(
  @ValidFileType(allowed = {"image/jpeg", "image/png"})
  @RequestParam("file") MultipartFile file
) {
  // File ƒë√£ ƒë∆∞·ª£c validate t·ª± ƒë·ªông
  return ResponseEntity.ok().build();
}
```

### ‚ùå C√°ch sai

```java
// ‚ùå BAD: Ch·ªâ check extension
public void validateFile(MultipartFile file) {
  String filename = file.getOriginalFilename();
  if (!filename.endsWith(".jpg") && !filename.endsWith(".png")) {
    throw new InvalidFileException("Ch·ªâ ch·∫•p nh·∫≠n JPG/PNG");
  }
  // Attacker upload virus.exe.jpg ‚Üí bypass!
}

// ‚ùå BAD: Ch·ªâ tin MIME type t·ª´ client
public void validateFile(MultipartFile file) {
  String contentType = file.getContentType();
  if (!"image/jpeg".equals(contentType)) {
    throw new InvalidFileException("Ch·ªâ ch·∫•p nh·∫≠n JPEG");
  }
  // Attacker gi·∫£ m·∫°o Content-Type header ‚Üí bypass!
}

// ‚ùå BAD: Kh√¥ng validate g√¨ c·∫£
@PostMapping("/upload")
public ResponseEntity<?> upload(@RequestParam("file") MultipartFile file) {
  fileService.save(file); // L∆∞u b·∫•t k·ª≥ file g√¨!
  return ResponseEntity.ok().build();
}
```

### Ph√°t hi·ªán

```bash
# T√¨m upload endpoint kh√¥ng c√≥ validation
rg -A 5 'MultipartFile' --type java | grep -v 'validate'

# T√¨m code ch·ªâ check extension
rg 'endsWith\("\.(jpg|png|pdf)' --type java

# T√¨m code ch·ªâ check contentType m√† kh√¥ng check magic bytes
rg 'getContentType\(\)' --type java | grep -v 'magic\|signature\|Tika'
```

### Checklist

- [ ] Validate extension (whitelist)
- [ ] Validate MIME type t·ª´ client
- [ ] Validate magic bytes (file signature)
- [ ] S·ª≠ d·ª•ng Apache Tika ho·∫∑c t∆∞∆°ng ƒë∆∞∆°ng
- [ ] Reject n·∫øu MIME type kh√¥ng kh·ªõp v·ªõi magic bytes
- [ ] C√≥ unit test cho bypass attempts

---

## 19.02 - Max file size limit (spring.servlet.multipart.max-file-size)

### Metadata
- **M·ª©c ƒë·ªô:** üî¥ B·∫ÆT BU·ªòC
- **L√Ω do:** DoS prevention, resource management
- **Impact:** HIGH - OOM, disk full, service down
- **Tags:** `security`, `resource-management`, `config`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- Upload file qu√° l·ªõn ‚Üí OOM
- L·∫•p ƒë·∫ßy disk space
- DoS attack b·∫±ng concurrent large uploads

**H·∫≠u qu·∫£ khi vi ph·∫°m:**
- Application crash do OOM
- Disk full ‚Üí service kh√¥ng ho·∫°t ƒë·ªông
- Network bandwidth b·ªã chi·∫øm d·ª•ng

### ‚úÖ C√°ch ƒë√∫ng

```yaml
# ‚úÖ GOOD: application.yml - Set gi·ªõi h·∫°n r√µ r√†ng
spring:
  servlet:
    multipart:
      enabled: true
      max-file-size: 10MB        # File ƒë∆°n l·∫ª t·ªëi ƒëa 10MB
      max-request-size: 50MB     # To√†n b·ªô request t·ªëi ƒëa 50MB (nhi·ªÅu file)
      file-size-threshold: 2MB   # > 2MB s·∫Ω ghi ra disk thay v√¨ memory
      location: /tmp/uploads     # Th∆∞ m·ª•c t·∫°m
```

```java
// ‚úÖ GOOD: Custom exception handler cho size limit
@ControllerAdvice
public class FileUploadExceptionHandler {

  @ExceptionHandler(MaxUploadSizeExceededException.class)
  public ResponseEntity<?> handleMaxSizeException(MaxUploadSizeExceededException ex) {
    return ResponseEntity
      .status(HttpStatus.PAYLOAD_TOO_LARGE)
      .body(Map.of(
        "error", "File qu√° l·ªõn",
        "message", "K√≠ch th∆∞·ªõc file t·ªëi ƒëa: 10MB",
        "timestamp", Instant.now()
      ));
  }

  @ExceptionHandler(SizeLimitExceededException.class)
  public ResponseEntity<?> handleSizeLimitException(SizeLimitExceededException ex) {
    return ResponseEntity
      .status(HttpStatus.PAYLOAD_TOO_LARGE)
      .body(Map.of(
        "error", "Request qu√° l·ªõn",
        "message", "T·ªïng k√≠ch th∆∞·ªõc request t·ªëi ƒëa: 50MB"
      ));
  }
}

// ‚úÖ GOOD: Validate size trong business logic
@Service
public class FileUploadService {

  @Value("${app.upload.max-size:10485760}") // 10MB default
  private long maxFileSize;

  public void validateFileSize(MultipartFile file) {
    if (file.getSize() > maxFileSize) {
      throw new FileSizeExceededException(
        "File %s v∆∞·ª£t qu√° gi·ªõi h·∫°n %d bytes"
          .formatted(file.getOriginalFilename(), maxFileSize)
      );
    }
  }

  public void upload(MultipartFile file) {
    validateFileSize(file);
    // Process upload...
  }
}

// ‚úÖ GOOD: Per-endpoint size limit
@PostMapping("/upload/avatar")
@RequestSizeLimit(maxSize = 2 * 1024 * 1024) // 2MB for avatar
public ResponseEntity<?> uploadAvatar(@RequestParam("file") MultipartFile file) {
  // Custom annotation ƒë·ªÉ enforce limit
  return ResponseEntity.ok().build();
}

// Custom annotation
@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
public @interface RequestSizeLimit {
  long maxSize();
}

@Aspect
@Component
public class RequestSizeLimitAspect {

  @Before("@annotation(limit)")
  public void checkSize(JoinPoint joinPoint, RequestSizeLimit limit) {
    Object[] args = joinPoint.getArgs();
    for (Object arg : args) {
      if (arg instanceof MultipartFile file) {
        if (file.getSize() > limit.maxSize()) {
          throw new FileSizeExceededException(
            "File v∆∞·ª£t qu√° %d bytes".formatted(limit.maxSize())
          );
        }
      }
    }
  }
}
```

### ‚ùå C√°ch sai

```yaml
# ‚ùå BAD: Kh√¥ng set limit (default l√† 1MB nh∆∞ng n√™n explicit)
spring:
  servlet:
    multipart:
      enabled: true
      # Kh√¥ng set max-file-size v√† max-request-size

# ‚ùå BAD: Limit qu√° l·ªõn
spring:
  servlet:
    multipart:
      max-file-size: 1GB  # Qu√° l·ªõn, d·ªÖ b·ªã DoS
      max-request-size: 5GB
```

```java
// ‚ùå BAD: Kh√¥ng validate size trong code
@PostMapping("/upload")
public ResponseEntity<?> upload(@RequestParam("file") MultipartFile file) {
  fileService.save(file); // Tin t∆∞·ªüng ho√†n to√†n v√†o config
  return ResponseEntity.ok().build();
}

// ‚ùå BAD: Load to√†n b·ªô file v√†o memory
public void processFile(MultipartFile file) {
  byte[] bytes = file.getBytes(); // OOM n·∫øu file l·ªõn
  // Process...
}
```

### Ph√°t hi·ªán

```bash
# T√¨m config thi·∫øu max-file-size
rg 'spring.servlet.multipart' config/ | grep -v 'max-file-size'

# T√¨m code load file v√†o memory
rg 'getBytes\(\)' --type java

# T√¨m upload endpoint kh√¥ng c√≥ size validation
rg '@PostMapping.*upload' -A 10 --type java | grep -v 'validateSize\|maxSize'
```

### Checklist

- [ ] Set `spring.servlet.multipart.max-file-size`
- [ ] Set `spring.servlet.multipart.max-request-size`
- [ ] Set `file-size-threshold` ƒë·ªÉ tr√°nh OOM
- [ ] Custom exception handler cho `MaxUploadSizeExceededException`
- [ ] Validate size trong business logic
- [ ] Document gi·ªõi h·∫°n cho frontend/API consumers
- [ ] Monitor disk space usage

---

## 19.03 - Virus scan tr∆∞·ªõc khi l∆∞u file

### Metadata
- **M·ª©c ƒë·ªô:** üü† KHUY·∫æN NGH·ªä
- **L√Ω do:** Security - ngƒÉn ch·∫∑n malware distribution
- **Impact:** MEDIUM - malware spread, data breach
- **Tags:** `security`, `malware`, `scanning`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- User c√≥ th·ªÉ upload file ch·ª©a virus/malware
- File b·ªã nhi·ªÖm c√≥ th·ªÉ l√¢y lan khi download
- Compliance requirement (GDPR, HIPAA, PCI-DSS)

**H·∫≠u qu·∫£ khi vi ph·∫°m:**
- Malware distribution platform
- Data breach, ransomware
- M·∫•t uy t√≠n, ki·ªán t·ª•ng

### ‚úÖ C√°ch ƒë√∫ng

```java
// ‚úÖ GOOD: ClamAV integration (open-source antivirus)
@Service
public class VirusScanService {

  private final ClamAVClient clamAVClient;

  public VirusScanService(
    @Value("${clamav.host:localhost}") String host,
    @Value("${clamav.port:3310}") int port
  ) {
    this.clamAVClient = new ClamAVClient(host, port);
  }

  public void scanFile(MultipartFile file) throws IOException {
    byte[] bytes = file.getBytes();
    byte[] reply = clamAVClient.scan(bytes);

    if (!ClamAVClient.isCleanReply(reply)) {
      String virusName = new String(reply).trim();
      throw new VirusDetectedException(
        "Ph√°t hi·ªán virus trong file %s: %s"
          .formatted(file.getOriginalFilename(), virusName)
      );
    }
  }
}

// ‚úÖ GOOD: Async virus scan v·ªõi callback
@Service
public class AsyncVirusScanService {

  private final VirusScanService virusScanService;
  private final FileStorageService fileStorageService;
  private final ApplicationEventPublisher eventPublisher;

  @Async
  public CompletableFuture<ScanResult> scanFileAsync(String fileId, byte[] content) {
    try {
      // Scan
      virusScanService.scan(content);

      // Mark file as safe
      fileStorageService.markAsSafe(fileId);

      // Publish event
      eventPublisher.publishEvent(new FileScanCompletedEvent(fileId, true));

      return CompletableFuture.completedFuture(ScanResult.CLEAN);
    } catch (VirusDetectedException e) {
      // Delete infected file
      fileStorageService.delete(fileId);

      // Publish event
      eventPublisher.publishEvent(new FileScanCompletedEvent(fileId, false, e.getVirusName()));

      return CompletableFuture.completedFuture(ScanResult.INFECTED);
    }
  }
}

// ‚úÖ GOOD: File quarantine workflow
@Service
public class FileUploadService {

  private final FileStorageService storageService;
  private final VirusScanService scanService;

  @Transactional
  public FileMetadata uploadFile(MultipartFile file) {
    // 1. Validate type, size
    validateFile(file);

    // 2. L∆∞u t·∫°m v√†o quarantine zone
    String quarantineId = storageService.saveToQuarantine(file);

    // 3. Scan virus
    try {
      scanService.scanFile(file);
    } catch (VirusDetectedException e) {
      storageService.deleteFromQuarantine(quarantineId);
      throw e;
    }

    // 4. Move t·ª´ quarantine sang production storage
    String finalId = storageService.moveToProduction(quarantineId);

    // 5. Save metadata
    return FileMetadata.builder()
      .id(finalId)
      .filename(file.getOriginalFilename())
      .status(FileStatus.SAFE)
      .scannedAt(Instant.now())
      .build();
  }
}

// ‚úÖ GOOD: Docker Compose setup cho ClamAV
/*
version: '3.8'
services:
  clamav:
    image: clamav/clamav:latest
    ports:
      - "3310:3310"
    volumes:
      - clamav-data:/var/lib/clamav
    environment:
      - CLAMAV_NO_FRESHCLAM=false  # Auto update virus definitions
volumes:
  clamav-data:
*/

// ‚úÖ GOOD: VirusTotal API integration (cloud-based)
@Service
public class VirusTotalScanService {

  private final WebClient webClient;

  @Value("${virustotal.api-key}")
  private String apiKey;

  public void scanFile(MultipartFile file) throws IOException {
    // 1. Upload file
    String analysisId = uploadFile(file);

    // 2. Poll for result
    ScanResult result = pollScanResult(analysisId);

    // 3. Check malicious count
    if (result.getMaliciousCount() > 0) {
      throw new VirusDetectedException(
        "File b·ªã ƒë√°nh d·∫•u malicious b·ªüi %d/%d antivirus engines"
          .formatted(result.getMaliciousCount(), result.getTotalEngines())
      );
    }
  }

  private String uploadFile(MultipartFile file) throws IOException {
    MultipartBodyBuilder builder = new MultipartBodyBuilder();
    builder.part("file", file.getResource());

    var response = webClient.post()
      .uri("https://www.virustotal.com/api/v3/files")
      .header("x-apikey", apiKey)
      .bodyValue(builder.build())
      .retrieve()
      .bodyToMono(JsonNode.class)
      .block();

    return response.get("data").get("id").asText();
  }

  private ScanResult pollScanResult(String analysisId) {
    // Poll every 10s, max 5 minutes
    for (int i = 0; i < 30; i++) {
      var response = webClient.get()
        .uri("https://www.virustotal.com/api/v3/analyses/{id}", analysisId)
        .header("x-apikey", apiKey)
        .retrieve()
        .bodyToMono(JsonNode.class)
        .block();

      String status = response.get("data").get("attributes").get("status").asText();
      if ("completed".equals(status)) {
        var stats = response.get("data").get("attributes").get("stats");
        return new ScanResult(
          stats.get("malicious").asInt(),
          stats.get("malicious").asInt() + stats.get("undetected").asInt()
        );
      }

      try {
        Thread.sleep(10_000);
      } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        throw new RuntimeException("Scan interrupted");
      }
    }

    throw new RuntimeException("Scan timeout");
  }
}
```

### ‚ùå C√°ch sai

```java
// ‚ùå BAD: Kh√¥ng scan virus
@PostMapping("/upload")
public ResponseEntity<?> upload(@RequestParam("file") MultipartFile file) {
  String fileId = storageService.save(file); // L∆∞u tr·ª±c ti·∫øp
  return ResponseEntity.ok(Map.of("fileId", fileId));
}

// ‚ùå BAD: Scan sau khi ƒë√£ public file
public String uploadFile(MultipartFile file) {
  String fileId = storageService.save(file);
  String publicUrl = storageService.getPublicUrl(fileId);

  // Scan async NH∆ØNG file ƒë√£ public!
  virusScanService.scanAsync(fileId);

  return publicUrl; // File c√≥ th·ªÉ b·ªã download tr∆∞·ªõc khi scan xong
}

// ‚ùå BAD: Ch·ªâ d·ª±a v√†o file extension ƒë·ªÉ quy·∫øt ƒë·ªãnh scan
public void uploadFile(MultipartFile file) {
  if (file.getOriginalFilename().endsWith(".exe")) {
    virusScanService.scan(file); // Ch·ªâ scan .exe
  }
  // Virus c√≥ th·ªÉ ·∫©n trong .jpg, .pdf, .docx, v.v.
  storageService.save(file);
}
```

### Ph√°t hi·ªán

```bash
# T√¨m upload service kh√¥ng c√≥ virus scan
rg 'class.*UploadService' -A 30 --type java | grep -v 'scan\|clamav\|virustotal'

# T√¨m code l∆∞u file tr·ª±c ti·∫øp m√† kh√¥ng scan
rg 'storageService.save' --type java | grep -v 'scan'

# Check ClamAV config
rg 'clamav' config/
```

### Checklist

- [ ] C√≥ virus scanning service (ClamAV, VirusTotal, ho·∫∑c t∆∞∆°ng ƒë∆∞∆°ng)
- [ ] Scan TR∆Ø·ªöC KHI file ƒë∆∞·ª£c public
- [ ] Quarantine workflow (t·∫°m l∆∞u ‚Üí scan ‚Üí move/delete)
- [ ] Async scan cho file l·ªõn
- [ ] Auto-update virus definitions
- [ ] Alert khi ph√°t hi·ªán virus
- [ ] Log scan results
- [ ] Handle scan timeout/failure

---

## 19.04 - Unique filename generation (UUID) tr√°nh overwrite

### Metadata
- **M·ª©c ƒë·ªô:** üü† KHUY·∫æN NGH·ªä
- **L√Ω do:** Data integrity, prevent overwrite, security
- **Impact:** MEDIUM - data loss, unauthorized access
- **Tags:** `security`, `data-integrity`, `naming`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- Filename tr√πng ‚Üí overwrite file c≈©
- Predictable filename ‚Üí enumeration attack
- Path traversal n·∫øu d√πng original filename

**H·∫≠u qu·∫£ khi vi ph·∫°m:**
- M·∫•t d·ªØ li·ªáu do overwrite
- Unauthorized access qua file enumeration
- Path traversal attack

### ‚úÖ C√°ch ƒë√∫ng

```java
// ‚úÖ GOOD: UUID-based filename generation
@Service
public class FileStorageService {

  @Value("${app.upload.dir:/var/app/uploads}")
  private String uploadDir;

  public FileMetadata store(MultipartFile file) throws IOException {
    // 1. Generate unique filename
    String originalFilename = file.getOriginalFilename();
    String extension = getExtension(originalFilename);
    String uniqueFilename = UUID.randomUUID() + extension;

    // 2. Create subdirectory by date (avoid too many files in one dir)
    LocalDate today = LocalDate.now();
    Path dateDir = Paths.get(uploadDir,
      String.valueOf(today.getYear()),
      String.format("%02d", today.getMonthValue()),
      String.format("%02d", today.getDayOfMonth())
    );
    Files.createDirectories(dateDir);

    // 3. Save file
    Path targetPath = dateDir.resolve(uniqueFilename);
    Files.copy(file.getInputStream(), targetPath, StandardCopyOption.REPLACE_EXISTING);

    // 4. Return metadata
    return FileMetadata.builder()
      .id(UUID.randomUUID().toString())
      .storedFilename(uniqueFilename)
      .originalFilename(sanitizeFilename(originalFilename))
      .path(targetPath.toString())
      .size(file.getSize())
      .contentType(file.getContentType())
      .uploadedAt(Instant.now())
      .build();
  }

  private String getExtension(String filename) {
    if (filename == null || !filename.contains(".")) {
      return "";
    }
    return filename.substring(filename.lastIndexOf('.'));
  }

  private String sanitizeFilename(String filename) {
    if (filename == null) return "unknown";

    // Remove path traversal attempts
    String sanitized = filename.replaceAll("\\.\\./", "");

    // Remove special characters
    sanitized = sanitized.replaceAll("[^a-zA-Z0-9._-]", "_");

    // Limit length
    if (sanitized.length() > 255) {
      sanitized = sanitized.substring(0, 255);
    }

    return sanitized;
  }
}

// ‚úÖ GOOD: ULID (sortable UUID alternative)
@Service
public class ULIDFilenameGenerator {

  private final UlidCreator ulidCreator = UlidCreator.getMonotonicCreator();

  public String generateFilename(String originalFilename) {
    String extension = getExtension(originalFilename);
    String ulid = ulidCreator.create().toString().toLowerCase();
    return ulid + extension;
  }

  // ULID benefits:
  // - 128-bit compatibility v·ªõi UUID
  // - Sortable by creation time
  // - Case-insensitive (base32)
  // - No special characters
}

// ‚úÖ GOOD: Hash-based filename (content-addressable)
@Service
public class HashBasedStorage {

  public FileMetadata store(MultipartFile file) throws IOException {
    byte[] content = file.getBytes();

    // 1. Hash file content (SHA-256)
    String hash = DigestUtils.sha256Hex(content);

    // 2. Check if file already exists (deduplication)
    Optional<FileMetadata> existing = fileRepository.findByHash(hash);
    if (existing.isPresent()) {
      return existing.get(); // Reuse existing file
    }

    // 3. Store with hash as filename
    String extension = getExtension(file.getOriginalFilename());
    String filename = hash + extension;

    // 4. Create subdirectory from hash prefix (avoid too many files)
    // /uploads/ab/cd/abcdef123456...
    Path subdir = Paths.get(uploadDir, hash.substring(0, 2), hash.substring(2, 4));
    Files.createDirectories(subdir);

    Path targetPath = subdir.resolve(filename);
    Files.write(targetPath, content);

    return FileMetadata.builder()
      .id(UUID.randomUUID().toString())
      .hash(hash)
      .storedFilename(filename)
      .originalFilename(file.getOriginalFilename())
      .path(targetPath.toString())
      .build();
  }
}

// ‚úÖ GOOD: Entity v·ªõi filename mapping
@Entity
@Table(name = "files")
public class FileMetadata {

  @Id
  @GeneratedValue(strategy = GenerationType.UUID)
  private String id; // Public ID cho client

  @Column(nullable = false, unique = true)
  private String storedFilename; // UUID + extension (internal)

  @Column(nullable = false)
  private String originalFilename; // User's filename (display only)

  @Column(nullable = false)
  private String path; // Full path tr√™n disk

  @Column(length = 64)
  private String hash; // SHA-256 hash (for deduplication)

  private Long size;
  private String contentType;

  @Column(nullable = false)
  private Instant uploadedAt;

  @Column(nullable = false)
  private String uploadedBy; // User ID
}
```

### ‚ùå C√°ch sai

```java
// ‚ùå BAD: D√πng original filename tr·ª±c ti·∫øp
public void store(MultipartFile file) throws IOException {
  String filename = file.getOriginalFilename(); // Nguy hi·ªÉm!
  Path path = Paths.get(uploadDir, filename);
  Files.copy(file.getInputStream(), path);
  // V·∫•n ƒë·ªÅ:
  // 1. Overwrite n·∫øu tr√πng t√™n
  // 2. Path traversal: ../../etc/passwd
  // 3. Predictable filename
}

// ‚ùå BAD: D√πng timestamp (c√≥ th·ªÉ tr√πng)
public String generateFilename(String originalFilename) {
  String extension = getExtension(originalFilename);
  long timestamp = System.currentTimeMillis();
  return timestamp + extension;
  // 2 requests c√πng millisecond ‚Üí overwrite!
}

// ‚ùå BAD: D√πng sequential ID
private AtomicLong counter = new AtomicLong(0);

public String generateFilename(String originalFilename) {
  long id = counter.incrementAndGet();
  return id + getExtension(originalFilename);
  // Enumeration attack: file/1, file/2, file/3, ...
}

// ‚ùå BAD: Sanitize kh√¥ng ƒë√∫ng c√°ch
public String sanitizeFilename(String filename) {
  return filename.replace("../", "");
  // Bypass: ....//
}
```

### Ph√°t hi·ªán

```bash
# T√¨m code d√πng original filename tr·ª±c ti·∫øp
rg 'getOriginalFilename\(\)' --type java | grep -v 'sanitize\|UUID\|hash'

# T√¨m code d√πng timestamp l√†m filename
rg 'currentTimeMillis\(\).*filename' --type java

# T√¨m code kh√¥ng c√≥ UUID/hash generation
rg 'class.*Storage' -A 30 --type java | grep -v 'UUID\|hash\|ulid'
```

### Checklist

- [ ] D√πng UUID/ULID/hash cho stored filename
- [ ] Kh√¥ng d√πng original filename l√†m stored filename
- [ ] Sanitize original filename n·∫øu c·∫ßn display
- [ ] Prevent path traversal (kh√¥ng d√πng user input trong path)
- [ ] Subdirectory structure (tr√°nh qu√° nhi·ªÅu file trong 1 th∆∞ m·ª•c)
- [ ] L∆∞u mapping gi·ªØa public ID v√† stored filename trong DB
- [ ] Consider deduplication (hash-based storage)

---

## 19.05 - L∆∞u file ngo√†i webroot (kh√¥ng serve tr·ª±c ti·∫øp)

### Metadata
- **M·ª©c ƒë·ªô:** üî¥ B·∫ÆT BU·ªòC
- **L√Ω do:** Security - ngƒÉn ch·∫∑n RCE, information disclosure
- **Impact:** HIGH - RCE, data breach, directory traversal
- **Tags:** `security`, `access-control`, `storage`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- File trong webroot c√≥ th·ªÉ execute tr·ª±c ti·∫øp (RCE)
- Directory listing l·ªô c·∫•u tr√∫c file
- Bypass authorization checks

**H·∫≠u qu·∫£ khi vi ph·∫°m:**
- RCE n·∫øu upload shell script
- Unauthorized access ƒë·∫øn file nh·∫°y c·∫£m
- Information disclosure

### ‚úÖ C√°ch ƒë√∫ng

```yaml
# ‚úÖ GOOD: application.yml - Upload dir ngo√†i webroot
app:
  upload:
    dir: /var/app-data/uploads  # Ngo√†i /var/www ho·∫∑c /opt/app
    max-size: 10MB
```

```java
// ‚úÖ GOOD: File serve qua controller v·ªõi authorization
@RestController
@RequestMapping("/api/files")
public class FileDownloadController {

  private final FileStorageService storageService;
  private final FileAuthorizationService authService;

  @GetMapping("/{fileId}")
  public ResponseEntity<Resource> downloadFile(
    @PathVariable String fileId,
    Authentication authentication
  ) {
    // 1. Load file metadata
    FileMetadata metadata = storageService.getMetadata(fileId);

    // 2. Check authorization
    if (!authService.canAccess(authentication, metadata)) {
      throw new AccessDeniedException("Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p file n√†y");
    }

    // 3. Load file t·ª´ storage (ngo√†i webroot)
    Resource resource = storageService.loadAsResource(fileId);

    // 4. Return v·ªõi proper headers
    return ResponseEntity.ok()
      .contentType(MediaType.parseMediaType(metadata.getContentType()))
      .header(HttpHeaders.CONTENT_DISPOSITION,
        "attachment; filename=\"" + metadata.getOriginalFilename() + "\"")
      .body(resource);
  }
}

// ‚úÖ GOOD: FileStorageService v·ªõi absolute path ngo√†i webroot
@Service
public class FileStorageService {

  private final Path uploadLocation;

  public FileStorageService(@Value("${app.upload.dir}") String uploadDir) {
    this.uploadLocation = Paths.get(uploadDir).toAbsolutePath().normalize();

    // Validate upload dir kh√¥ng n·∫±m trong webroot
    Path webRoot = Paths.get("src/main/resources/static").toAbsolutePath();
    if (uploadLocation.startsWith(webRoot)) {
      throw new IllegalStateException(
        "Upload dir KH√îNG ƒê∆Ø·ª¢C n·∫±m trong webroot: " + uploadLocation
      );
    }

    try {
      Files.createDirectories(uploadLocation);
    } catch (IOException e) {
      throw new RuntimeException("Kh√¥ng t·∫°o ƒë∆∞·ª£c upload directory", e);
    }
  }

  public Resource loadAsResource(String fileId) {
    FileMetadata metadata = fileRepository.findById(fileId)
      .orElseThrow(() -> new FileNotFoundException("File kh√¥ng t·ªìn t·∫°i: " + fileId));

    Path filePath = Paths.get(metadata.getPath()).normalize();

    // CRITICAL: Validate path kh√¥ng escape kh·ªèi upload dir (path traversal prevention)
    if (!filePath.startsWith(uploadLocation)) {
      throw new SecurityException("Ph√°t hi·ªán path traversal attempt: " + filePath);
    }

    try {
      Resource resource = new UrlResource(filePath.toUri());
      if (resource.exists() && resource.isReadable()) {
        return resource;
      } else {
        throw new FileNotFoundException("File kh√¥ng ƒë·ªçc ƒë∆∞·ª£c: " + fileId);
      }
    } catch (MalformedURLException e) {
      throw new RuntimeException("Invalid file path", e);
    }
  }
}

// ‚úÖ GOOD: Inline display v·ªõi Content-Security-Policy
@GetMapping("/{fileId}/inline")
public ResponseEntity<Resource> viewFile(@PathVariable String fileId) {
  FileMetadata metadata = storageService.getMetadata(fileId);
  Resource resource = storageService.loadAsResource(fileId);

  return ResponseEntity.ok()
    .contentType(MediaType.parseMediaType(metadata.getContentType()))
    // CSP ngƒÉn ch·∫∑n XSS n·∫øu file l√† HTML
    .header("Content-Security-Policy", "default-src 'none'; style-src 'unsafe-inline';")
    // X-Content-Type-Options ngƒÉn MIME sniffing
    .header("X-Content-Type-Options", "nosniff")
    // Inline display
    .header(HttpHeaders.CONTENT_DISPOSITION, "inline; filename=\"" + metadata.getOriginalFilename() + "\"")
    .body(resource);
}

// ‚úÖ GOOD: Security config - Disable directory listing
@Configuration
public class WebSecurityConfig {

  @Bean
  public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
    http
      // ...
      .authorizeHttpRequests(auth -> auth
        .requestMatchers("/uploads/**").denyAll() // Block direct access
        .requestMatchers("/api/files/**").authenticated()
        .anyRequest().permitAll()
      );

    return http.build();
  }
}

// ‚úÖ GOOD: Docker volume mount (file ngo√†i container filesystem)
/*
version: '3.8'
services:
  app:
    image: myapp:latest
    volumes:
      - /host/data/uploads:/var/app-data/uploads:rw  # External mount
    environment:
      - APP_UPLOAD_DIR=/var/app-data/uploads
*/
```

### ‚ùå C√°ch sai

```yaml
# ‚ùå BAD: Upload dir trong webroot
app:
  upload:
    dir: src/main/resources/static/uploads  # Trong webroot!
    # File c√≥ th·ªÉ access tr·ª±c ti·∫øp: http://localhost:8080/uploads/file.jsp
```

```java
// ‚ùå BAD: Serve file tr·ª±c ti·∫øp t·ª´ static resources
@Configuration
public class WebMvcConfig implements WebMvcConfigurer {

  @Override
  public void addResourceHandlers(ResourceHandlerRegistry registry) {
    registry.addResourceHandler("/uploads/**")
      .addResourceLocations("file:/var/uploads/");
    // Kh√¥ng c√≥ authorization check!
    // Directory listing c√≥ th·ªÉ b·∫≠t!
  }
}

// ‚ùå BAD: Kh√¥ng validate path (path traversal)
@GetMapping("/download")
public ResponseEntity<Resource> download(@RequestParam String filename) {
  Path path = Paths.get(uploadDir, filename); // User input tr·ª±c ti·∫øp!
  // Attacker: ?filename=../../../../etc/passwd
  Resource resource = new UrlResource(path.toUri());
  return ResponseEntity.ok().body(resource);
}

// ‚ùå BAD: L∆∞u file upload trong classpath
public void store(MultipartFile file) throws IOException {
  Path path = Paths.get("src/main/resources/uploads", file.getOriginalFilename());
  Files.copy(file.getInputStream(), path);
  // File trong classpath c√≥ th·ªÉ ƒë∆∞·ª£c load b·ªüi ClassLoader ‚Üí RCE risk
}
```

### Ph√°t hi·ªán

```bash
# T√¨m upload dir trong static resources
rg 'resources/static' config/ --type yaml

# T√¨m ResourceHandler serve file upload
rg 'addResourceHandlers' --type java -A 5 | grep uploads

# T√¨m code kh√¥ng validate path traversal
rg 'Paths.get.*filename' --type java | grep -v 'normalize\|startsWith'

# T√¨m file access kh√¥ng c√≥ authorization
rg '@GetMapping.*download' -A 10 --type java | grep -v 'canAccess\|authorize\|checkPermission'
```

### Checklist

- [ ] Upload dir n·∫±m ngo√†i webroot (/var/app-data, /opt/data, v.v.)
- [ ] Kh√¥ng d√πng `static/uploads` ho·∫∑c `public/uploads`
- [ ] Serve file qua controller v·ªõi authorization check
- [ ] Validate path traversal (normalize + startsWith check)
- [ ] Set proper Content-Security-Policy headers
- [ ] Disable directory listing
- [ ] Block direct access ƒë·∫øn upload dir (`/uploads/**` ‚Üí deny)
- [ ] Log file access for audit

---

## 19.06 - Presigned URL cho cloud storage download

### Metadata
- **M·ª©c ƒë·ªô:** üü† KHUY·∫æN NGH·ªä
- **L√Ω do:** Performance, security, scalability
- **Impact:** MEDIUM - server load, bandwidth cost
- **Tags:** `cloud`, `performance`, `s3`, `security`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- Download qua application server t·ªën bandwidth
- Kh√¥ng t·∫≠n d·ª•ng CDN c·ªßa cloud provider
- Expose credentials n·∫øu d√πng public bucket

**L·ª£i √≠ch:**
- Direct download t·ª´ S3/Azure Blob (faster)
- Time-limited access (security)
- Gi·∫£m load cho application server

### ‚úÖ C√°ch ƒë√∫ng

```java
// ‚úÖ GOOD: AWS S3 presigned URL
@Service
public class S3FileStorageService {

  private final S3Client s3Client;
  private final String bucketName;

  public S3FileStorageService(
    @Value("${aws.s3.bucket}") String bucketName,
    @Value("${aws.region}") String region
  ) {
    this.bucketName = bucketName;
    this.s3Client = S3Client.builder()
      .region(Region.of(region))
      .build();
  }

  public String uploadFile(MultipartFile file) throws IOException {
    String key = UUID.randomUUID() + getExtension(file.getOriginalFilename());

    PutObjectRequest putRequest = PutObjectRequest.builder()
      .bucket(bucketName)
      .key(key)
      .contentType(file.getContentType())
      .metadata(Map.of(
        "original-filename", file.getOriginalFilename(),
        "uploaded-by", SecurityContextHolder.getContext().getAuthentication().getName()
      ))
      .build();

    s3Client.putObject(putRequest, RequestBody.fromBytes(file.getBytes()));

    return key;
  }

  public String generatePresignedUrl(String fileKey, Duration expiration) {
    S3Presigner presigner = S3Presigner.create();

    GetObjectRequest getRequest = GetObjectRequest.builder()
      .bucket(bucketName)
      .key(fileKey)
      .build();

    GetObjectPresignRequest presignRequest = GetObjectPresignRequest.builder()
      .signatureDuration(expiration) // V√≠ d·ª•: 15 ph√∫t
      .getObjectRequest(getRequest)
      .build();

    PresignedGetObjectRequest presignedRequest = presigner.presignGetObject(presignRequest);

    return presignedRequest.url().toString();
  }
}

// ‚úÖ GOOD: Controller tr·∫£ v·ªÅ presigned URL
@RestController
@RequestMapping("/api/files")
public class FileController {

  private final S3FileStorageService storageService;
  private final FileAuthorizationService authService;

  @GetMapping("/{fileId}/download-url")
  public ResponseEntity<?> getDownloadUrl(
    @PathVariable String fileId,
    Authentication authentication
  ) {
    // 1. Check authorization
    FileMetadata metadata = fileRepository.findById(fileId)
      .orElseThrow(() -> new FileNotFoundException(fileId));

    if (!authService.canAccess(authentication, metadata)) {
      throw new AccessDeniedException("Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p file n√†y");
    }

    // 2. Generate presigned URL (valid for 15 minutes)
    String presignedUrl = storageService.generatePresignedUrl(
      metadata.getS3Key(),
      Duration.ofMinutes(15)
    );

    // 3. Return URL
    return ResponseEntity.ok(Map.of(
      "downloadUrl", presignedUrl,
      "expiresIn", 900, // seconds
      "filename", metadata.getOriginalFilename()
    ));
  }
}

// ‚úÖ GOOD: Azure Blob Storage presigned URL (SAS token)
@Service
public class AzureBlobStorageService {

  private final BlobServiceClient blobServiceClient;
  private final String containerName;

  public AzureBlobStorageService(
    @Value("${azure.storage.connection-string}") String connectionString,
    @Value("${azure.storage.container}") String containerName
  ) {
    this.blobServiceClient = new BlobServiceClientBuilder()
      .connectionString(connectionString)
      .buildClient();
    this.containerName = containerName;
  }

  public String uploadFile(MultipartFile file) throws IOException {
    String blobName = UUID.randomUUID() + getExtension(file.getOriginalFilename());

    BlobContainerClient containerClient = blobServiceClient.getBlobContainerClient(containerName);
    BlobClient blobClient = containerClient.getBlobClient(blobName);

    blobClient.upload(file.getInputStream(), file.getSize(), true);

    return blobName;
  }

  public String generateSasUrl(String blobName, Duration expiration) {
    BlobContainerClient containerClient = blobServiceClient.getBlobContainerClient(containerName);
    BlobClient blobClient = containerClient.getBlobClient(blobName);

    OffsetDateTime expiryTime = OffsetDateTime.now().plus(expiration);

    BlobSasPermission permission = new BlobSasPermission().setReadPermission(true);

    BlobServiceSasSignatureValues sasValues = new BlobServiceSasSignatureValues(expiryTime, permission);

    String sasToken = blobClient.generateSas(sasValues);

    return blobClient.getBlobUrl() + "?" + sasToken;
  }
}

// ‚úÖ GOOD: Caching presigned URL (v·ªõi expiration check)
@Service
public class PresignedUrlCacheService {

  private final LoadingCache<String, CachedPresignedUrl> urlCache;
  private final S3FileStorageService storageService;

  public PresignedUrlCacheService(S3FileStorageService storageService) {
    this.storageService = storageService;
    this.urlCache = Caffeine.newBuilder()
      .expireAfterWrite(10, TimeUnit.MINUTES) // Cache 10 ph√∫t
      .maximumSize(10_000)
      .build(this::generatePresignedUrl);
  }

  private CachedPresignedUrl generatePresignedUrl(String fileKey) {
    String url = storageService.generatePresignedUrl(fileKey, Duration.ofMinutes(15));
    Instant expiresAt = Instant.now().plus(Duration.ofMinutes(15));
    return new CachedPresignedUrl(url, expiresAt);
  }

  public String getPresignedUrl(String fileKey) {
    CachedPresignedUrl cached = urlCache.get(fileKey);

    // N·∫øu s·∫Øp h·∫øt h·∫°n (< 2 ph√∫t), regenerate
    if (cached.expiresAt().isBefore(Instant.now().plus(Duration.ofMinutes(2)))) {
      urlCache.invalidate(fileKey);
      cached = urlCache.get(fileKey);
    }

    return cached.url();
  }

  record CachedPresignedUrl(String url, Instant expiresAt) {}
}

// ‚úÖ GOOD: Frontend usage
/*
// React example
const downloadFile = async (fileId) => {
  // 1. Get presigned URL
  const response = await fetch(`/api/files/${fileId}/download-url`);
  const { downloadUrl, filename } = await response.json();

  // 2. Download directly from S3 (kh√¥ng qua backend)
  const link = document.createElement('a');
  link.href = downloadUrl;
  link.download = filename;
  link.click();
};
*/
```

### ‚ùå C√°ch sai

```java
// ‚ùå BAD: Download file qua application server
@GetMapping("/{fileId}/download")
public ResponseEntity<byte[]> download(@PathVariable String fileId) {
  FileMetadata metadata = fileRepository.findById(fileId).orElseThrow();

  // Download t·ª´ S3 v√†o memory
  byte[] content = s3Client.getObject(metadata.getS3Key()).readAllBytes();

  // G·ª≠i qua response
  return ResponseEntity.ok()
    .header(HttpHeaders.CONTENT_DISPOSITION, "attachment; filename=\"" + metadata.getOriginalFilename() + "\"")
    .body(content);

  // V·∫•n ƒë·ªÅ:
  // - T·ªën bandwidth c·ªßa application server
  // - T·ªën memory (load to√†n b·ªô file v√†o RAM)
  // - Ch·∫≠m h∆°n direct download t·ª´ S3
}

// ‚ùå BAD: Public S3 bucket (kh√¥ng c·∫ßn auth)
public String uploadFile(MultipartFile file) {
  String key = UUID.randomUUID().toString();

  PutObjectRequest request = PutObjectRequest.builder()
    .bucket(bucketName)
    .key(key)
    .acl(ObjectCannedACL.PUBLIC_READ) // Public!
    .build();

  s3Client.putObject(request, RequestBody.fromBytes(file.getBytes()));

  return "https://%s.s3.amazonaws.com/%s".formatted(bucketName, key);
  // Ai c≈©ng c√≥ th·ªÉ access!
}

// ‚ùå BAD: Presigned URL kh√¥ng c√≥ expiration limit
public String generatePresignedUrl(String key) {
  return storageService.generatePresignedUrl(key, Duration.ofDays(365)); // 1 nƒÉm!
  // URL leak ‚Üí access forever
}

// ‚ùå BAD: Kh√¥ng check authorization tr∆∞·ªõc khi t·∫°o presigned URL
@GetMapping("/{fileId}/download-url")
public ResponseEntity<?> getDownloadUrl(@PathVariable String fileId) {
  FileMetadata metadata = fileRepository.findById(fileId).orElseThrow();
  String url = storageService.generatePresignedUrl(metadata.getS3Key());
  return ResponseEntity.ok(Map.of("url", url));
  // Kh√¥ng check quy·ªÅn ‚Üí b·∫•t k·ª≥ ai bi·∫øt fileId ƒë·ªÅu download ƒë∆∞·ª£c!
}
```

### Ph√°t hi·ªán

```bash
# T√¨m download qua controller m√† kh√¥ng d√πng presigned URL
rg '@GetMapping.*download' -A 15 --type java | grep 'getObject\|downloadFile' | grep -v 'presign'

# T√¨m S3 public ACL
rg 'PUBLIC_READ\|PUBLIC_WRITE' --type java

# T√¨m presigned URL v·ªõi expiration qu√° d√†i
rg 'generatePresignedUrl.*Duration.of(Days|Hours)\([^1-9]' --type java
```

### Checklist

- [ ] D√πng presigned URL cho download t·ª´ cloud storage
- [ ] Expiration time h·ª£p l√Ω (5-30 ph√∫t)
- [ ] Check authorization TR∆Ø·ªöC KHI t·∫°o presigned URL
- [ ] Cache presigned URL (v·ªõi expiration check)
- [ ] Private S3 bucket/Azure container (kh√¥ng public)
- [ ] Log presigned URL generation for audit
- [ ] Handle expiration gracefully ·ªü frontend

---

## 19.07 - Streaming upload cho file l·ªõn (kh√¥ng load v√†o memory)

### Metadata
- **M·ª©c ƒë·ªô:** üü† KHUY·∫æN NGH·ªä
- **L√Ω do:** Performance, prevent OOM
- **Impact:** MEDIUM - OOM, slow upload, poor UX
- **Tags:** `performance`, `memory`, `streaming`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- Load to√†n b·ªô file v√†o memory ‚Üí OOM
- Blocking I/O ch·∫≠m cho file l·ªõn
- Kh√¥ng th·ªÉ upload file > available memory

**L·ª£i √≠ch:**
- Constant memory usage (O(1))
- H·ªó tr·ª£ file k√≠ch th∆∞·ªõc l·ªõn
- Better performance

### ‚úÖ C√°ch ƒë√∫ng

```java
// ‚úÖ GOOD: Streaming upload l√™n S3
@Service
public class StreamingS3UploadService {

  private final S3Client s3Client;
  private final String bucketName;

  public String uploadStream(MultipartFile file) throws IOException {
    String key = UUID.randomUUID() + getExtension(file.getOriginalFilename());

    // Streaming upload (kh√¥ng load to√†n b·ªô v√†o memory)
    PutObjectRequest putRequest = PutObjectRequest.builder()
      .bucket(bucketName)
      .key(key)
      .contentType(file.getContentType())
      .contentLength(file.getSize())
      .build();

    // RequestBody.fromInputStream t·ª± ƒë·ªông streaming
    s3Client.putObject(putRequest, RequestBody.fromInputStream(
      file.getInputStream(),
      file.getSize()
    ));

    return key;
  }
}

// ‚úÖ GOOD: Multipart upload cho file r·∫•t l·ªõn (>100MB)
@Service
public class MultipartS3UploadService {

  private final S3Client s3Client;
  private final String bucketName;

  public String uploadLargeFile(MultipartFile file) throws IOException {
    String key = UUID.randomUUID() + getExtension(file.getOriginalFilename());

    // 1. Initiate multipart upload
    CreateMultipartUploadRequest createRequest = CreateMultipartUploadRequest.builder()
      .bucket(bucketName)
      .key(key)
      .contentType(file.getContentType())
      .build();

    CreateMultipartUploadResponse createResponse = s3Client.createMultipartUpload(createRequest);
    String uploadId = createResponse.uploadId();

    try {
      // 2. Upload parts (5MB m·ªói part)
      int partSize = 5 * 1024 * 1024; // 5MB
      List<CompletedPart> completedParts = new ArrayList<>();

      try (InputStream inputStream = file.getInputStream()) {
        byte[] buffer = new byte[partSize];
        int partNumber = 1;
        int bytesRead;

        while ((bytesRead = inputStream.read(buffer)) > 0) {
          ByteArrayInputStream partStream = new ByteArrayInputStream(buffer, 0, bytesRead);

          UploadPartRequest uploadPartRequest = UploadPartRequest.builder()
            .bucket(bucketName)
            .key(key)
            .uploadId(uploadId)
            .partNumber(partNumber)
            .contentLength((long) bytesRead)
            .build();

          UploadPartResponse uploadPartResponse = s3Client.uploadPart(
            uploadPartRequest,
            RequestBody.fromInputStream(partStream, bytesRead)
          );

          completedParts.add(CompletedPart.builder()
            .partNumber(partNumber)
            .eTag(uploadPartResponse.eTag())
            .build());

          partNumber++;
        }
      }

      // 3. Complete multipart upload
      CompleteMultipartUploadRequest completeRequest = CompleteMultipartUploadRequest.builder()
        .bucket(bucketName)
        .key(key)
        .uploadId(uploadId)
        .multipartUpload(CompletedMultipartUpload.builder().parts(completedParts).build())
        .build();

      s3Client.completeMultipartUpload(completeRequest);

      return key;
    } catch (Exception e) {
      // Abort multipart upload n·∫øu c√≥ l·ªói
      AbortMultipartUploadRequest abortRequest = AbortMultipartUploadRequest.builder()
        .bucket(bucketName)
        .key(key)
        .uploadId(uploadId)
        .build();
      s3Client.abortMultipartUpload(abortRequest);

      throw new RuntimeException("Upload failed", e);
    }
  }
}

// ‚úÖ GOOD: Local file storage v·ªõi streaming
@Service
public class StreamingFileStorageService {

  @Value("${app.upload.dir}")
  private String uploadDir;

  public String uploadStream(MultipartFile file) throws IOException {
    String filename = UUID.randomUUID() + getExtension(file.getOriginalFilename());
    Path targetPath = Paths.get(uploadDir, filename);

    // Streaming copy (kh√¥ng load v√†o memory)
    try (InputStream inputStream = file.getInputStream()) {
      Files.copy(inputStream, targetPath, StandardCopyOption.REPLACE_EXISTING);
    }

    return filename;
  }

  public void downloadStream(String filename, HttpServletResponse response) throws IOException {
    Path path = Paths.get(uploadDir, filename);

    if (!Files.exists(path)) {
      throw new FileNotFoundException(filename);
    }

    // Streaming download
    response.setContentType(Files.probeContentType(path));
    response.setHeader(HttpHeaders.CONTENT_DISPOSITION, "attachment; filename=\"" + filename + "\"");
    response.setContentLengthLong(Files.size(path));

    try (InputStream inputStream = Files.newInputStream(path);
         OutputStream outputStream = response.getOutputStream()) {
      inputStream.transferTo(outputStream);
    }
  }
}

// ‚úÖ GOOD: Controller v·ªõi StreamingResponseBody
@RestController
@RequestMapping("/api/files")
public class StreamingDownloadController {

  private final FileStorageService storageService;

  @GetMapping("/{fileId}/stream")
  public ResponseEntity<StreamingResponseBody> streamDownload(@PathVariable String fileId) {
    FileMetadata metadata = fileRepository.findById(fileId).orElseThrow();
    Path filePath = Paths.get(metadata.getPath());

    StreamingResponseBody stream = outputStream -> {
      try (InputStream inputStream = Files.newInputStream(filePath)) {
        byte[] buffer = new byte[8192]; // 8KB buffer
        int bytesRead;
        while ((bytesRead = inputStream.read(buffer)) != -1) {
          outputStream.write(buffer, 0, bytesRead);
        }
      }
    };

    return ResponseEntity.ok()
      .contentType(MediaType.parseMediaType(metadata.getContentType()))
      .contentLength(metadata.getSize())
      .header(HttpHeaders.CONTENT_DISPOSITION, "attachment; filename=\"" + metadata.getOriginalFilename() + "\"")
      .body(stream);
  }
}

// ‚úÖ GOOD: Resumable upload (tus protocol)
@RestController
@RequestMapping("/api/files/resumable")
public class ResumableUploadController {

  private final Map<String, UploadSession> sessions = new ConcurrentHashMap<>();

  @PostMapping
  public ResponseEntity<?> createUploadSession(@RequestHeader("Upload-Length") long fileSize) {
    String sessionId = UUID.randomUUID().toString();
    Path tempPath = Paths.get("/tmp", sessionId);

    UploadSession session = new UploadSession(sessionId, fileSize, tempPath, 0);
    sessions.put(sessionId, session);

    return ResponseEntity.status(HttpStatus.CREATED)
      .header("Upload-ID", sessionId)
      .build();
  }

  @PatchMapping("/{sessionId}")
  public ResponseEntity<?> uploadChunk(
    @PathVariable String sessionId,
    @RequestHeader("Upload-Offset") long offset,
    @RequestBody byte[] chunk
  ) throws IOException {
    UploadSession session = sessions.get(sessionId);
    if (session == null) {
      return ResponseEntity.notFound().build();
    }

    // Validate offset
    if (offset != session.currentOffset()) {
      return ResponseEntity.status(HttpStatus.CONFLICT).build();
    }

    // Append chunk
    try (FileOutputStream fos = new FileOutputStream(session.tempPath().toFile(), true)) {
      fos.write(chunk);
    }

    session.incrementOffset(chunk.length);

    // Check if complete
    if (session.currentOffset() >= session.totalSize()) {
      // Move to permanent storage
      String finalPath = storageService.finalize(session.tempPath());
      sessions.remove(sessionId);

      return ResponseEntity.ok(Map.of("fileId", finalPath));
    }

    return ResponseEntity.status(HttpStatus.NO_CONTENT)
      .header("Upload-Offset", String.valueOf(session.currentOffset()))
      .build();
  }

  record UploadSession(String id, long totalSize, Path tempPath, long currentOffset) {
    void incrementOffset(long bytes) {
      // Update offset (simplified, use AtomicLong in production)
    }
  }
}
```

### ‚ùå C√°ch sai

```java
// ‚ùå BAD: Load to√†n b·ªô file v√†o memory
public String uploadFile(MultipartFile file) throws IOException {
  byte[] bytes = file.getBytes(); // OOM n·∫øu file l·ªõn!

  String key = UUID.randomUUID().toString();
  s3Client.putObject(key, RequestBody.fromBytes(bytes));

  return key;
}

// ‚ùå BAD: Download v√†o memory tr∆∞·ªõc khi g·ª≠i response
@GetMapping("/{fileId}/download")
public ResponseEntity<byte[]> download(@PathVariable String fileId) {
  FileMetadata metadata = fileRepository.findById(fileId).orElseThrow();

  byte[] content = Files.readAllBytes(Paths.get(metadata.getPath())); // OOM!

  return ResponseEntity.ok()
    .body(content);
}

// ‚ùå BAD: Blocking I/O cho file l·ªõn
public void processLargeFile(MultipartFile file) throws IOException {
  // Load to√†n b·ªô v√†o List
  List<String> lines = new BufferedReader(new InputStreamReader(file.getInputStream()))
    .lines()
    .collect(Collectors.toList()); // OOM n·∫øu file c√≥ nhi·ªÅu tri·ªáu d√≤ng!

  // Process...
}
```

### Ph√°t hi·ªán

```bash
# T√¨m code load file v√†o memory
rg 'getBytes\(\)|readAllBytes' --type java

# T√¨m upload kh√¥ng d√πng streaming
rg 'putObject.*RequestBody.from(Bytes|String)' --type java

# T√¨m download kh√¥ng streaming
rg 'ResponseEntity.*byte\[\]' --type java
```

### Checklist

- [ ] D√πng streaming cho upload (kh√¥ng load v√†o memory)
- [ ] D√πng streaming cho download (StreamingResponseBody)
- [ ] Multipart upload cho file > 100MB
- [ ] Proper buffer size (8KB - 64KB)
- [ ] Handle upload interruption (resumable upload)
- [ ] Monitor memory usage khi upload/download
- [ ] Cleanup temp files n·∫øu upload failed

---

## 19.08 - Cleanup orphaned files (scheduled task)

### Metadata
- **M·ª©c ƒë·ªô:** üü° N√äN C√ì
- **L√Ω do:** Resource management, cost optimization
- **Impact:** LOW - disk waste, storage cost
- **Tags:** `maintenance`, `cleanup`, `scheduling`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- Upload th√†nh c√¥ng nh∆∞ng transaction rollback
- User x√≥a record trong DB nh∆∞ng file v·∫´n c√≤n
- Temp files kh√¥ng ƒë∆∞·ª£c cleanup

**H·∫≠u qu·∫£:**
- L√£ng ph√≠ disk space
- TƒÉng chi ph√≠ cloud storage
- Performance degradation (qu√° nhi·ªÅu file)

### ‚úÖ C√°ch ƒë√∫ng

```java
// ‚úÖ GOOD: Scheduled task cleanup orphaned files
@Component
@Slf4j
public class OrphanedFileCleanupJob {

  private final FileRepository fileRepository;
  private final FileStorageService storageService;

  @Value("${app.cleanup.orphan-age-days:7}")
  private int orphanAgeDays;

  // Ch·∫°y h√†ng ng√†y l√∫c 2 AM
  @Scheduled(cron = "0 0 2 * * *")
  @Transactional
  public void cleanupOrphanedFiles() {
    log.info("Starting orphaned file cleanup job...");

    Instant cutoffTime = Instant.now().minus(Duration.ofDays(orphanAgeDays));

    // 1. T√¨m files trong storage
    List<String> storedFiles = storageService.listAllFiles();
    log.info("Found {} files in storage", storedFiles.size());

    // 2. T√¨m files trong DB
    Set<String> referencedFiles = fileRepository.findAll()
      .stream()
      .map(FileMetadata::getStoredFilename)
      .collect(Collectors.toSet());
    log.info("Found {} files referenced in DB", referencedFiles.size());

    // 3. T√¨m orphaned files
    List<String> orphanedFiles = storedFiles.stream()
      .filter(file -> !referencedFiles.contains(file))
      .toList();

    log.info("Found {} orphaned files", orphanedFiles.size());

    // 4. Delete orphaned files (older than cutoff)
    int deletedCount = 0;
    for (String orphanedFile : orphanedFiles) {
      try {
        Instant lastModified = storageService.getLastModifiedTime(orphanedFile);
        if (lastModified.isBefore(cutoffTime)) {
          storageService.delete(orphanedFile);
          deletedCount++;
          log.debug("Deleted orphaned file: {}", orphanedFile);
        }
      } catch (Exception e) {
        log.error("Failed to delete orphaned file: {}", orphanedFile, e);
      }
    }

    log.info("Cleanup completed. Deleted {} orphaned files", deletedCount);
  }
}

// ‚úÖ GOOD: Soft delete v·ªõi expiration
@Entity
@Table(name = "files")
public class FileMetadata {

  @Id
  private String id;

  private String storedFilename;

  @Column(nullable = false)
  private Instant uploadedAt;

  private Instant deletedAt; // NULL = active

  private Instant expiresAt; // Auto-delete after this time

  @Column(nullable = false)
  private FileStatus status; // PENDING, ACTIVE, DELETED
}

@Component
@Slf4j
public class SoftDeletedFileCleanupJob {

  private final FileRepository fileRepository;
  private final FileStorageService storageService;

  @Value("${app.cleanup.soft-delete-retention-days:30}")
  private int retentionDays;

  @Scheduled(cron = "0 0 3 * * *") // 3 AM daily
  @Transactional
  public void cleanupSoftDeletedFiles() {
    Instant cutoffTime = Instant.now().minus(Duration.ofDays(retentionDays));

    // T√¨m files ƒë√£ soft delete > 30 ng√†y
    List<FileMetadata> filesToDelete = fileRepository
      .findByDeletedAtBeforeAndStatus(cutoffTime, FileStatus.DELETED);

    log.info("Found {} soft-deleted files to permanently delete", filesToDelete.size());

    for (FileMetadata file : filesToDelete) {
      try {
        // Delete from storage
        storageService.delete(file.getStoredFilename());

        // Delete from DB
        fileRepository.delete(file);

        log.debug("Permanently deleted file: {}", file.getId());
      } catch (Exception e) {
        log.error("Failed to delete file: {}", file.getId(), e);
      }
    }
  }
}

// ‚úÖ GOOD: Cleanup expired files
@Component
@Slf4j
public class ExpiredFileCleanupJob {

  private final FileRepository fileRepository;
  private final FileStorageService storageService;

  @Scheduled(cron = "0 */15 * * * *") // Every 15 minutes
  @Transactional
  public void cleanupExpiredFiles() {
    Instant now = Instant.now();

    // T√¨m files ƒë√£ h·∫øt h·∫°n
    List<FileMetadata> expiredFiles = fileRepository
      .findByExpiresAtBeforeAndStatus(now, FileStatus.ACTIVE);

    log.info("Found {} expired files", expiredFiles.size());

    for (FileMetadata file : expiredFiles) {
      try {
        // Delete from storage
        storageService.delete(file.getStoredFilename());

        // Update status ho·∫∑c delete record
        file.setStatus(FileStatus.EXPIRED);
        file.setDeletedAt(now);
        fileRepository.save(file);

        log.debug("Cleaned up expired file: {}", file.getId());
      } catch (Exception e) {
        log.error("Failed to cleanup expired file: {}", file.getId(), e);
      }
    }
  }
}

// ‚úÖ GOOD: Cleanup temp upload files
@Component
@Slf4j
public class TempFileCleanupJob {

  @Value("${app.upload.temp-dir:/tmp/uploads}")
  private String tempDir;

  @Scheduled(cron = "0 0 * * * *") // Every hour
  public void cleanupTempFiles() throws IOException {
    Path tempPath = Paths.get(tempDir);

    if (!Files.exists(tempPath)) return;

    Instant cutoffTime = Instant.now().minus(Duration.ofHours(1));

    try (var stream = Files.walk(tempPath)) {
      List<Path> oldFiles = stream
        .filter(Files::isRegularFile)
        .filter(path -> {
          try {
            FileTime lastModified = Files.getLastModifiedTime(path);
            return lastModified.toInstant().isBefore(cutoffTime);
          } catch (IOException e) {
            return false;
          }
        })
        .toList();

      log.info("Found {} temp files older than 1 hour", oldFiles.size());

      for (Path file : oldFiles) {
        try {
          Files.delete(file);
          log.debug("Deleted temp file: {}", file);
        } catch (IOException e) {
          log.error("Failed to delete temp file: {}", file, e);
        }
      }
    }
  }
}

// ‚úÖ GOOD: Monitor storage usage
@Component
@Slf4j
public class StorageUsageMonitor {

  private final FileRepository fileRepository;
  private final MeterRegistry meterRegistry;

  @Scheduled(cron = "0 */5 * * * *") // Every 5 minutes
  public void updateStorageMetrics() {
    // Total file count
    long totalFiles = fileRepository.count();
    meterRegistry.gauge("storage.files.total", totalFiles);

    // Total size
    long totalSize = fileRepository.sumFileSize();
    meterRegistry.gauge("storage.size.bytes", totalSize);

    // Count by status
    Map<FileStatus, Long> countByStatus = fileRepository.countByStatus();
    countByStatus.forEach((status, count) ->
      meterRegistry.gauge("storage.files.by_status", Tags.of("status", status.name()), count)
    );

    log.debug("Storage metrics updated: {} files, {} bytes", totalFiles, totalSize);
  }
}
```

### ‚ùå C√°ch sai

```java
// ‚ùå BAD: Kh√¥ng c√≥ cleanup job
// Files b·ªã orphaned t√≠ch t·ª• m√£i m√£i

// ‚ùå BAD: Delete file tr∆∞·ªõc khi delete DB record
@Transactional
public void deleteFile(String fileId) {
  FileMetadata metadata = fileRepository.findById(fileId).orElseThrow();

  // Delete file tr∆∞·ªõc
  storageService.delete(metadata.getStoredFilename());

  // Delete DB record sau (n·∫øu exception ‚Üí orphaned record)
  fileRepository.delete(metadata);
}

// ‚ùå BAD: Hard delete ngay l·∫≠p t·ª©c (kh√¥ng soft delete)
public void deleteFile(String fileId) {
  FileMetadata metadata = fileRepository.findById(fileId).orElseThrow();
  storageService.delete(metadata.getStoredFilename()); // Kh√¥ng th·ªÉ recover!
  fileRepository.delete(metadata);
}

// ‚ùå BAD: Cleanup job kh√¥ng c√≥ timeout/batch limit
@Scheduled(cron = "0 0 2 * * *")
public void cleanup() {
  List<String> allFiles = storageService.listAllFiles(); // Millions of files!

  for (String file : allFiles) {
    // Process t·ª´ng file ‚Üí timeout, OOM
  }
}
```

### Ph√°t hi·ªán

```bash
# T√¨m project kh√¥ng c√≥ @Scheduled cleanup job
rg '@Scheduled' --type java | grep -i cleanup

# T√¨m delete file m√† kh√¥ng soft delete
rg 'storageService.delete' --type java | grep -v 'deletedAt\|soft'

# T√¨m code delete file tr∆∞·ªõc DB record
rg 'delete.*file.*repository.delete' -A 5 --type java
```

### Checklist

- [ ] Scheduled job cleanup orphaned files
- [ ] Soft delete v·ªõi retention period
- [ ] Cleanup expired files (n·∫øu c√≥ TTL)
- [ ] Cleanup temp upload files
- [ ] Monitor storage usage metrics
- [ ] Batch processing (kh√¥ng load t·∫•t c·∫£ v√†o memory)
- [ ] Error handling v√† retry logic
- [ ] Alert khi storage usage cao

---

## 19.09 - Image resize/compress tr∆∞·ªõc khi l∆∞u

### Metadata
- **M·ª©c ƒë·ªô:** üü° N√äN C√ì
- **L√Ω do:** Performance, cost optimization, UX
- **Impact:** LOW - storage cost, bandwidth, loading time
- **Tags:** `optimization`, `image`, `performance`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- User upload ·∫£nh 10MB t·ª´ smartphone
- Display ·∫£nh ch·ªâ c·∫ßn 200KB (thumbnail)
- L√£ng ph√≠ bandwidth v√† storage

**L·ª£i √≠ch:**
- Gi·∫£m storage cost
- Faster page load
- Better UX (especially mobile)

### ‚úÖ C√°ch ƒë√∫ng

```java
// ‚úÖ GOOD: Image resize v·ªõi Thumbnailator
@Service
public class ImageProcessingService {

  @Value("${app.image.max-width:1920}")
  private int maxWidth;

  @Value("${app.image.max-height:1080}")
  private int maxHeight;

  @Value("${app.image.quality:0.85}")
  private float quality;

  public byte[] resizeImage(MultipartFile file) throws IOException {
    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();

    Thumbnails.of(file.getInputStream())
      .size(maxWidth, maxHeight)
      .outputFormat("jpg")
      .outputQuality(quality)
      .toOutputStream(outputStream);

    return outputStream.toByteArray();
  }

  public byte[] createThumbnail(MultipartFile file, int width, int height) throws IOException {
    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();

    Thumbnails.of(file.getInputStream())
      .size(width, height)
      .crop(Positions.CENTER) // Crop to exact size
      .outputFormat("jpg")
      .outputQuality(0.8f)
      .toOutputStream(outputStream);

    return outputStream.toByteArray();
  }
}

// ‚úÖ GOOD: Multi-size image storage (responsive images)
@Service
public class ImageUploadService {

  private final ImageProcessingService imageProcessing;
  private final FileStorageService storageService;

  @Transactional
  public ImageMetadata uploadImage(MultipartFile file) throws IOException {
    // Validate image type
    if (!isImage(file)) {
      throw new InvalidFileException("File kh√¥ng ph·∫£i ·∫£nh");
    }

    // Generate base ID
    String baseId = UUID.randomUUID().toString();

    // 1. Original (resize n·∫øu qu√° l·ªõn)
    byte[] original = imageProcessing.resizeImage(file);
    String originalKey = storageService.save(baseId + "_original.jpg", original);

    // 2. Large (1200x800)
    byte[] large = imageProcessing.createThumbnail(file, 1200, 800);
    String largeKey = storageService.save(baseId + "_large.jpg", large);

    // 3. Medium (800x600)
    byte[] medium = imageProcessing.createThumbnail(file, 800, 600);
    String mediumKey = storageService.save(baseId + "_medium.jpg", medium);

    // 4. Small (400x300)
    byte[] small = imageProcessing.createThumbnail(file, 400, 300);
    String smallKey = storageService.save(baseId + "_small.jpg", small);

    // 5. Thumbnail (150x150)
    byte[] thumbnail = imageProcessing.createThumbnail(file, 150, 150);
    String thumbnailKey = storageService.save(baseId + "_thumb.jpg", thumbnail);

    // Save metadata
    return ImageMetadata.builder()
      .id(baseId)
      .originalKey(originalKey)
      .largeKey(largeKey)
      .mediumKey(mediumKey)
      .smallKey(smallKey)
      .thumbnailKey(thumbnailKey)
      .originalFilename(file.getOriginalFilename())
      .build();
  }

  private boolean isImage(MultipartFile file) {
    String contentType = file.getContentType();
    return contentType != null && contentType.startsWith("image/");
  }
}

// ‚úÖ GOOD: Async image processing
@Service
public class AsyncImageProcessingService {

  private final ImageProcessingService imageProcessing;
  private final FileStorageService storageService;
  private final ApplicationEventPublisher eventPublisher;

  @Async
  public CompletableFuture<ImageMetadata> processImageAsync(String uploadId, MultipartFile file) {
    try {
      // 1. L∆∞u original t·∫°m
      String tempKey = storageService.saveTemp(uploadId, file.getBytes());

      // 2. Process c√°c size variants
      ImageMetadata metadata = createImageVariants(uploadId, file);

      // 3. Delete temp file
      storageService.delete(tempKey);

      // 4. Publish event
      eventPublisher.publishEvent(new ImageProcessedEvent(uploadId, metadata));

      return CompletableFuture.completedFuture(metadata);
    } catch (Exception e) {
      eventPublisher.publishEvent(new ImageProcessingFailedEvent(uploadId, e.getMessage()));
      throw new CompletionException(e);
    }
  }

  private ImageMetadata createImageVariants(String baseId, MultipartFile file) throws IOException {
    // Similar to uploadImage() above
    // ...
    return null;
  }
}

// ‚úÖ GOOD: WebP format support (better compression)
@Service
public class WebPImageService {

  public byte[] convertToWebP(MultipartFile file) throws IOException {
    // S·ª≠ d·ª•ng libwebp ho·∫∑c imageio-webp
    BufferedImage image = ImageIO.read(file.getInputStream());

    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
    ImageWriter writer = ImageIO.getImageWritersByMIMEType("image/webp").next();

    ImageWriteParam writeParam = writer.getDefaultWriteParam();
    writeParam.setCompressionMode(ImageWriteParam.MODE_EXPLICIT);
    writeParam.setCompressionQuality(0.85f);

    ImageOutputStream ios = ImageIO.createImageOutputStream(outputStream);
    writer.setOutput(ios);
    writer.write(null, new IIOImage(image, null, null), writeParam);

    writer.dispose();
    ios.close();

    return outputStream.toByteArray();
  }
}

// ‚úÖ GOOD: Controller tr·∫£ v·ªÅ responsive image URLs
@RestController
@RequestMapping("/api/images")
public class ImageController {

  @GetMapping("/{imageId}")
  public ResponseEntity<?> getImage(@PathVariable String imageId) {
    ImageMetadata metadata = imageRepository.findById(imageId).orElseThrow();

    return ResponseEntity.ok(Map.of(
      "id", metadata.getId(),
      "urls", Map.of(
        "original", generateUrl(metadata.getOriginalKey()),
        "large", generateUrl(metadata.getLargeKey()),
        "medium", generateUrl(metadata.getMediumKey()),
        "small", generateUrl(metadata.getSmallKey()),
        "thumbnail", generateUrl(metadata.getThumbnailKey())
      ),
      "srcset", generateSrcSet(metadata)
    ));
  }

  private String generateSrcSet(ImageMetadata metadata) {
    return String.join(", ",
      generateUrl(metadata.getSmallKey()) + " 400w",
      generateUrl(metadata.getMediumKey()) + " 800w",
      generateUrl(metadata.getLargeKey()) + " 1200w",
      generateUrl(metadata.getOriginalKey()) + " 1920w"
    );
  }
}

// ‚úÖ GOOD: Frontend usage
/*
<img
  src="/api/images/123/medium"
  srcset="/api/images/123/srcset"
  sizes="(max-width: 600px) 400px, (max-width: 1200px) 800px, 1200px"
  alt="Responsive image"
/>
*/
```

### ‚ùå C√°ch sai

```java
// ‚ùå BAD: L∆∞u original image kh√¥ng resize
@PostMapping("/upload/image")
public ResponseEntity<?> uploadImage(@RequestParam MultipartFile file) {
  String key = storageService.save(file); // L∆∞u 10MB original!
  return ResponseEntity.ok(Map.of("imageUrl", key));
}

// ‚ùå BAD: Resize on-the-fly khi request
@GetMapping("/images/{id}/thumbnail")
public ResponseEntity<byte[]> getThumbnail(@PathVariable String id) {
  byte[] original = storageService.load(id); // Load 10MB
  byte[] thumbnail = imageProcessing.resize(original, 150, 150); // Resize m·ªói request!
  return ResponseEntity.ok(thumbnail);
  // Waste CPU, slow response time
}

// ‚ùå BAD: Kh√¥ng maintain aspect ratio
public byte[] resize(byte[] image, int width, int height) {
  // Force exact size ‚Üí image b·ªã m√©o
  return Thumbnails.of(new ByteArrayInputStream(image))
    .forceSize(width, height) // ‚ùå forceSize
    .asBytes();
}

// ‚ùå BAD: Quality qu√° cao ho·∫∑c qu√° th·∫•p
Thumbnails.of(file)
  .size(800, 600)
  .outputQuality(1.0f) // 100% quality ‚Üí file size l·ªõn kh√¥ng c·∫ßn thi·∫øt
  .toOutputStream(out);

Thumbnails.of(file)
  .size(800, 600)
  .outputQuality(0.3f) // 30% quality ‚Üí ·∫£nh m·ªù, blocky
  .toOutputStream(out);
```

### Ph√°t hi·ªán

```bash
# T√¨m upload image m√† kh√¥ng resize
rg '@PostMapping.*image.*upload' -A 15 --type java | grep -v 'resize\|thumbnail\|compress'

# T√¨m code resize on-the-fly
rg '@GetMapping.*thumbnail' -A 10 --type java | grep 'resize'

# T√¨m Thumbnailator usage v·ªõi bad quality
rg 'outputQuality\((0\.[0-3]|1\.0)' --type java
```

### Checklist

- [ ] Resize image tr∆∞·ªõc khi l∆∞u (max width/height)
- [ ] Generate multiple sizes (original, large, medium, small, thumbnail)
- [ ] Proper quality setting (0.8 - 0.9)
- [ ] Maintain aspect ratio
- [ ] Support WebP format
- [ ] Async processing cho image variants
- [ ] Return responsive image URLs (srcset)
- [ ] Consider lazy loading

---

## 19.10 - Storage abstraction layer (local ‚Üî S3 ‚Üî Azure Blob)

### Metadata
- **M·ª©c ƒë·ªô:** üü° N√äN C√ì
- **L√Ω do:** Flexibility, testability, vendor lock-in prevention
- **Impact:** LOW - vendor lock-in, testing difficulty
- **Tags:** `architecture`, `abstraction`, `cloud-agnostic`

### T·∫°i sao?

**V·∫•n ƒë·ªÅ:**
- Vendor lock-in (kh√≥ migrate t·ª´ S3 sang Azure)
- Kh√≥ test (ph·ª• thu·ªôc v√†o cloud service)
- Duplicate code cho m·ªói storage backend

**L·ª£i √≠ch:**
- Easy migration gi·ªØa cloud providers
- Testable (mock storage)
- Consistent API

### ‚úÖ C√°ch ƒë√∫ng

```java
// ‚úÖ GOOD: Storage abstraction interface
public interface FileStorageService {

  /**
   * Upload file v√† tr·∫£ v·ªÅ storage key
   */
  String upload(String filename, InputStream inputStream, long size, String contentType) throws IOException;

  /**
   * Upload file t·ª´ MultipartFile
   */
  default String upload(MultipartFile file) throws IOException {
    return upload(
      file.getOriginalFilename(),
      file.getInputStream(),
      file.getSize(),
      file.getContentType()
    );
  }

  /**
   * Download file
   */
  InputStream download(String key) throws IOException;

  /**
   * Delete file
   */
  void delete(String key) throws IOException;

  /**
   * Check if file exists
   */
  boolean exists(String key);

  /**
   * Get file metadata
   */
  StorageMetadata getMetadata(String key) throws IOException;

  /**
   * Generate presigned URL (n·∫øu h·ªó tr·ª£)
   */
  Optional<String> generatePresignedUrl(String key, Duration expiration);

  /**
   * List files v·ªõi prefix
   */
  List<String> list(String prefix);
}

record StorageMetadata(
  String key,
  long size,
  String contentType,
  Instant lastModified
) {}

// ‚úÖ GOOD: Local filesystem implementation
@Service
@ConditionalOnProperty(name = "app.storage.type", havingValue = "local", matchIfMissing = true)
public class LocalFileStorageService implements FileStorageService {

  private final Path uploadLocation;

  public LocalFileStorageService(@Value("${app.upload.dir:/var/app/uploads}") String uploadDir) {
    this.uploadLocation = Paths.get(uploadDir).toAbsolutePath().normalize();

    try {
      Files.createDirectories(uploadLocation);
    } catch (IOException e) {
      throw new RuntimeException("Could not create upload directory", e);
    }
  }

  @Override
  public String upload(String filename, InputStream inputStream, long size, String contentType) throws IOException {
    String key = UUID.randomUUID() + "_" + filename;
    Path targetPath = uploadLocation.resolve(key);

    Files.copy(inputStream, targetPath, StandardCopyOption.REPLACE_EXISTING);

    return key;
  }

  @Override
  public InputStream download(String key) throws IOException {
    Path path = uploadLocation.resolve(key).normalize();

    if (!path.startsWith(uploadLocation)) {
      throw new SecurityException("Path traversal attempt: " + key);
    }

    if (!Files.exists(path)) {
      throw new FileNotFoundException("File not found: " + key);
    }

    return Files.newInputStream(path);
  }

  @Override
  public void delete(String key) throws IOException {
    Path path = uploadLocation.resolve(key).normalize();

    if (!path.startsWith(uploadLocation)) {
      throw new SecurityException("Path traversal attempt: " + key);
    }

    Files.deleteIfExists(path);
  }

  @Override
  public boolean exists(String key) {
    Path path = uploadLocation.resolve(key).normalize();
    return path.startsWith(uploadLocation) && Files.exists(path);
  }

  @Override
  public StorageMetadata getMetadata(String key) throws IOException {
    Path path = uploadLocation.resolve(key).normalize();

    if (!Files.exists(path)) {
      throw new FileNotFoundException("File not found: " + key);
    }

    return new StorageMetadata(
      key,
      Files.size(path),
      Files.probeContentType(path),
      Files.getLastModifiedTime(path).toInstant()
    );
  }

  @Override
  public Optional<String> generatePresignedUrl(String key, Duration expiration) {
    // Local storage kh√¥ng h·ªó tr·ª£ presigned URL
    return Optional.empty();
  }

  @Override
  public List<String> list(String prefix) {
    try (var stream = Files.walk(uploadLocation)) {
      return stream
        .filter(Files::isRegularFile)
        .map(uploadLocation::relativize)
        .map(Path::toString)
        .filter(name -> prefix == null || name.startsWith(prefix))
        .toList();
    } catch (IOException e) {
      throw new RuntimeException("Failed to list files", e);
    }
  }
}

// ‚úÖ GOOD: S3 implementation
@Service
@ConditionalOnProperty(name = "app.storage.type", havingValue = "s3")
public class S3FileStorageService implements FileStorageService {

  private final S3Client s3Client;
  private final S3Presigner s3Presigner;
  private final String bucketName;

  public S3FileStorageService(
    @Value("${aws.s3.bucket}") String bucketName,
    @Value("${aws.region}") String region
  ) {
    this.bucketName = bucketName;
    this.s3Client = S3Client.builder()
      .region(Region.of(region))
      .build();
    this.s3Presigner = S3Presigner.builder()
      .region(Region.of(region))
      .build();
  }

  @Override
  public String upload(String filename, InputStream inputStream, long size, String contentType) throws IOException {
    String key = UUID.randomUUID() + "_" + filename;

    PutObjectRequest putRequest = PutObjectRequest.builder()
      .bucket(bucketName)
      .key(key)
      .contentType(contentType)
      .contentLength(size)
      .build();

    s3Client.putObject(putRequest, RequestBody.fromInputStream(inputStream, size));

    return key;
  }

  @Override
  public InputStream download(String key) throws IOException {
    GetObjectRequest getRequest = GetObjectRequest.builder()
      .bucket(bucketName)
      .key(key)
      .build();

    return s3Client.getObject(getRequest);
  }

  @Override
  public void delete(String key) {
    DeleteObjectRequest deleteRequest = DeleteObjectRequest.builder()
      .bucket(bucketName)
      .key(key)
      .build();

    s3Client.deleteObject(deleteRequest);
  }

  @Override
  public boolean exists(String key) {
    try {
      HeadObjectRequest headRequest = HeadObjectRequest.builder()
        .bucket(bucketName)
        .key(key)
        .build();

      s3Client.headObject(headRequest);
      return true;
    } catch (NoSuchKeyException e) {
      return false;
    }
  }

  @Override
  public StorageMetadata getMetadata(String key) throws IOException {
    HeadObjectRequest headRequest = HeadObjectRequest.builder()
      .bucket(bucketName)
      .key(key)
      .build();

    HeadObjectResponse response = s3Client.headObject(headRequest);

    return new StorageMetadata(
      key,
      response.contentLength(),
      response.contentType(),
      response.lastModified()
    );
  }

  @Override
  public Optional<String> generatePresignedUrl(String key, Duration expiration) {
    GetObjectRequest getRequest = GetObjectRequest.builder()
      .bucket(bucketName)
      .key(key)
      .build();

    GetObjectPresignRequest presignRequest = GetObjectPresignRequest.builder()
      .signatureDuration(expiration)
      .getObjectRequest(getRequest)
      .build();

    PresignedGetObjectRequest presigned = s3Presigner.presignGetObject(presignRequest);

    return Optional.of(presigned.url().toString());
  }

  @Override
  public List<String> list(String prefix) {
    ListObjectsV2Request listRequest = ListObjectsV2Request.builder()
      .bucket(bucketName)
      .prefix(prefix)
      .build();

    ListObjectsV2Response response = s3Client.listObjectsV2(listRequest);

    return response.contents().stream()
      .map(S3Object::key)
      .toList();
  }
}

// ‚úÖ GOOD: Azure Blob Storage implementation
@Service
@ConditionalOnProperty(name = "app.storage.type", havingValue = "azure")
public class AzureBlobStorageService implements FileStorageService {

  private final BlobServiceClient blobServiceClient;
  private final String containerName;

  public AzureBlobStorageService(
    @Value("${azure.storage.connection-string}") String connectionString,
    @Value("${azure.storage.container}") String containerName
  ) {
    this.blobServiceClient = new BlobServiceClientBuilder()
      .connectionString(connectionString)
      .buildClient();
    this.containerName = containerName;
  }

  @Override
  public String upload(String filename, InputStream inputStream, long size, String contentType) {
    String blobName = UUID.randomUUID() + "_" + filename;

    BlobContainerClient containerClient = blobServiceClient.getBlobContainerClient(containerName);
    BlobClient blobClient = containerClient.getBlobClient(blobName);

    blobClient.upload(inputStream, size, true);

    return blobName;
  }

  @Override
  public InputStream download(String key) {
    BlobClient blobClient = getBlobClient(key);
    return blobClient.openInputStream();
  }

  @Override
  public void delete(String key) {
    BlobClient blobClient = getBlobClient(key);
    blobClient.delete();
  }

  @Override
  public boolean exists(String key) {
    BlobClient blobClient = getBlobClient(key);
    return blobClient.exists();
  }

  @Override
  public StorageMetadata getMetadata(String key) {
    BlobClient blobClient = getBlobClient(key);
    BlobProperties properties = blobClient.getProperties();

    return new StorageMetadata(
      key,
      properties.getBlobSize(),
      properties.getContentType(),
      properties.getLastModified().toInstant()
    );
  }

  @Override
  public Optional<String> generatePresignedUrl(String key, Duration expiration) {
    BlobClient blobClient = getBlobClient(key);

    OffsetDateTime expiryTime = OffsetDateTime.now().plus(expiration);
    BlobSasPermission permission = new BlobSasPermission().setReadPermission(true);
    BlobServiceSasSignatureValues sasValues = new BlobServiceSasSignatureValues(expiryTime, permission);

    String sasToken = blobClient.generateSas(sasValues);
    String url = blobClient.getBlobUrl() + "?" + sasToken;

    return Optional.of(url);
  }

  @Override
  public List<String> list(String prefix) {
    BlobContainerClient containerClient = blobServiceClient.getBlobContainerClient(containerName);

    return containerClient.listBlobsByHierarchy(prefix).stream()
      .map(item -> item.getName())
      .toList();
  }

  private BlobClient getBlobClient(String blobName) {
    BlobContainerClient containerClient = blobServiceClient.getBlobContainerClient(containerName);
    return containerClient.getBlobClient(blobName);
  }
}

// ‚úÖ GOOD: Configuration
@Configuration
public class StorageConfiguration {

  @Bean
  @ConditionalOnProperty(name = "app.storage.type", havingValue = "local", matchIfMissing = true)
  public FileStorageService localFileStorageService() {
    return new LocalFileStorageService();
  }

  @Bean
  @ConditionalOnProperty(name = "app.storage.type", havingValue = "s3")
  public FileStorageService s3FileStorageService() {
    return new S3FileStorageService();
  }

  @Bean
  @ConditionalOnProperty(name = "app.storage.type", havingValue = "azure")
  public FileStorageService azureBlobStorageService() {
    return new AzureBlobStorageService();
  }
}

// application.yml
/*
app:
  storage:
    type: ${STORAGE_TYPE:local}  # local, s3, azure
  upload:
    dir: /var/app/uploads  # For local storage

aws:
  s3:
    bucket: my-bucket
  region: us-east-1

azure:
  storage:
    connection-string: ${AZURE_STORAGE_CONNECTION_STRING}
    container: uploads
*/
```

### ‚ùå C√°ch sai

```java
// ‚ùå BAD: Hardcode S3 client ·ªü nhi·ªÅu n∆°i
@Service
public class FileUploadService {

  @Autowired
  private S3Client s3Client; // Tight coupling v·ªõi S3!

  public String uploadFile(MultipartFile file) {
    // S3-specific code
    PutObjectRequest request = PutObjectRequest.builder()
      .bucket("my-bucket")
      .key(UUID.randomUUID().toString())
      .build();

    s3Client.putObject(request, RequestBody.fromBytes(file.getBytes()));

    // Kh√¥ng th·ªÉ d·ªÖ d√†ng switch sang Azure ho·∫∑c local storage
  }
}

// ‚ùå BAD: Kh√¥ng c√≥ abstraction, m·ªói service t·ª± implement
@Service
public class ProfileService {
  @Autowired private S3Client s3Client;

  public void uploadAvatar(MultipartFile file) {
    // Duplicate S3 logic
  }
}

@Service
public class DocumentService {
  @Autowired private S3Client s3Client;

  public void uploadDocument(MultipartFile file) {
    // Duplicate S3 logic (again!)
  }
}

// ‚ùå BAD: Kh√¥ng d√πng @ConditionalOnProperty
@Configuration
public class StorageConfig {

  @Bean
  public FileStorageService fileStorageService() {
    // Hardcoded implementation
    return new S3FileStorageService();
    // Ph·∫£i s·ª≠a code ƒë·ªÉ switch implementation!
  }
}
```

### Ph√°t hi·ªán

```bash
# T√¨m direct usage c·ªßa S3Client/BlobClient
rg '@Autowired.*S3Client|@Autowired.*BlobClient' --type java

# T√¨m service kh√¥ng d√πng abstraction interface
rg 'class.*Service.*{' -A 10 --type java | grep 'S3Client\|BlobClient' | grep -v 'implements FileStorageService'

# T√¨m hardcoded bucket/container names
rg '"[a-z-]+-bucket"|"[a-z-]+-container"' --type java | grep -v '@Value'
```

### Checklist

- [ ] Storage abstraction interface (FileStorageService)
- [ ] Multiple implementations (Local, S3, Azure, GCS)
- [ ] Configuration-driven selection (@ConditionalOnProperty)
- [ ] Consistent API across implementations
- [ ] Easy to test (mock interface)
- [ ] No direct usage c·ªßa cloud SDK ·ªü business logic
- [ ] Support presigned URLs (n·∫øu cloud storage h·ªó tr·ª£)
- [ ] Migration path documented

---

## T·ªïng k·∫øt Domain 19: File Storage & Upload

### Priority Matrix

| M·ª©c ƒë·ªô | Practices | Tr·ªçng s·ªë |
|--------|-----------|----------|
| üî¥ B·∫ÆT BU·ªòC | 19.01, 19.02, 19.05 | √ó3 |
| üü† KHUY·∫æN NGH·ªä | 19.03, 19.04, 19.06, 19.07 | √ó2 |
| üü° N√äN C√ì | 19.08, 19.09, 19.10 | √ó1 |

### Quick Checklist

**Security (CRITICAL):**
- [ ] File type validation (MIME + magic bytes)
- [ ] Max file size limit
- [ ] Virus scan
- [ ] L∆∞u file ngo√†i webroot
- [ ] Authorization check tr∆∞·ªõc khi serve file

**Performance:**
- [ ] Streaming upload/download
- [ ] Presigned URL cho cloud storage
- [ ] Image resize/compress
- [ ] Multipart upload cho file l·ªõn

**Maintenance:**
- [ ] Cleanup orphaned files
- [ ] Soft delete v·ªõi retention
- [ ] Storage metrics monitoring

**Architecture:**
- [ ] Storage abstraction layer
- [ ] Unique filename generation
- [ ] Cloud-agnostic design

### Anti-patterns ph·ªï bi·∫øn

1. ‚ùå Ch·ªâ validate extension, kh√¥ng validate magic bytes
2. ‚ùå Load file v√†o memory (getBytes()) thay v√¨ streaming
3. ‚ùå L∆∞u file trong webroot (RCE risk)
4. ‚ùå Download qua application server thay v√¨ presigned URL
5. ‚ùå Kh√¥ng cleanup orphaned files
6. ‚ùå Hardcode cloud SDK thay v√¨ abstraction layer

### Tools & Libraries

| Tool | Purpose |
|------|---------|
| Apache Tika | MIME type detection |
| ClamAV | Virus scanning |
| Thumbnailator | Image resize |
| AWS S3 SDK | S3 integration |
| Azure Blob SDK | Azure Blob integration |
| Spring Multipart | File upload handling |
